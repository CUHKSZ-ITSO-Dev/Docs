---
hide:
  - navigation
  - toc
---

# Conversational Models

Conversational models are those available for selection in the model dropdown menu located in the upper-left corner of the interface. [^5]

| Model Series             | Model Name                       | Underlying Model                    | Model Type     | Strengths                                                | Context Length (Tokens) | Response Speed | Pricing   | Price (per 1M Tokens)                  | Brand          | Deployment          |
| ------------------------ | -------------------------------- | ----------------------------------- | -------------- | -------------------------------------------------------- | ----------------------- | -------------- | --------- | -------------------------------------- | -------------- | ------------------- |
| **Qwen**                 | Qwen3-MoE (Local Edition)    | `qwen3-vl-235b-a22b-instruct`       | Multimodal     | General conversation                                     | 128,000                 | Fast           | **Free**  | Input/Cache/Output: ￥2.00/ ￥0.50/ ￥8.00 (free on platform) | Alibaba        | On-premise          |
| **DeepSeek**             | DeepSeek                         | `DeepSeek V3 671B`                  | Multimodal[^1] | General conversation                                     | 96,000                  | Medium         | Low       | Input/Cache/Output: ￥2.00/￥0.40/￥8.00    | DeepSeek       | API (Volcano Cloud) |
| **DeepSeek**             | DeepSeek (Deep Thinking Enabled) | `DeepSeek R1 671B`                  | Multimodal[^1] | Complex math, complex reasoning                          | 64,000                  | Slow           | Low       | Input/Cache/Output: ￥4.00/￥0.80/￥16.00   | DeepSeek       | API (Volcano Cloud) |
| **GPT**                  | GPT-5 Auto[^6]                   | `GPT-5 Chat`                        | Multimodal     | General conversation, automated reasoning, fast response | 128,000                 | Fast           | Medium    | Input/Cache/Output: \$1.25/\$0.125/\$10.00 | OpenAI         | API (Azure)         |
| **GPT**                  | GPT-5 Thinking                   | `GPT-5`                             | Multimodal     | Complex reasoning, deep thinking, problem analysis       | 400,000                 | Slow           | High      | Input/Cache/Output: \$1.25/\$0.125/\$10.00 | OpenAI         | API (Azure)         |
| **GPT**                  | GPT-4.1                          | `GPT-4.1`                           | Multimodal     | Programming, long context, general reasoning             | 1,047,576               | Medium         | High      | Input/Cache/Output: \$2.00/\$0.50/\$8.00    | OpenAI         | API (Azure)         |
| **Gemini**               | Gemini 2.5 Pro                   | `Gemini 2.5 Pro`                    | Multimodal     | General chat, multimodal understanding                   | 128,000                 | Medium         | High      | Input/Cache/Output: \$2.50/\$0.625/\$15.00 | Google         | API (Google)        |
| **Gemini**               | Gemini 2.5 Flash                 | `Gemini 2.5 Flash`                  | Multimodal     | General chat, fast responses                             | 128,000                 | Fast           | Low       | Input/Cache/Output: \$0.30/\$0.075/\$2.50   | Google         | API (Google)        |
| **Doubao Seed**          | Doubao Seed 1.6              | `Doubao Seed 1.6`                   | Multimodal     | General conversation                                     | 96,000                  | Medium         | Medium    | Input/Cache/Output: ￥0.80/￥0.16/￥8.00    | Volcano Engine | API (Volcano Cloud) |
| **OpenAI Deep Research** | OpenAI Deep Research[^7]         | `OpenAI Deep Research`              | /              | Web search and information synthesis                     | N/A                      | Very Slow      | Very High | Input/Cache/Output: \$10.00/\$2.50/\$40.00 | OpenAI         | API (Azure)         |

<!-- Not yet launched -->
<!-- | **xAI**                 | Grok-4                          | `grok-4`                            | Multimodal     | General chat, reasoning                                  | Medium         | High      | Input/Cache/Output: \$3.00/\$3.00/\$15.00   | xAI            | API (xAI)           | -->
<!-- | **Doubao Seed**         | Doubao Seed 1.6 Thinking              | `doubao-seed-1-6-thinking-250715`   | Multimodal[^1] | Complex reasoning, deep thinking                         | Slow           | High      | Input/Cache/Output: ￥1.20/￥0.16/￥16.00   | Volcano Engine | API (Volcano Cloud) | -->

#

# Foundational Models

These models support the core functionalities of the GPT platform.

| Model Series               | Underlying Model            | Model Type | Purpose                                                 | Strengths                                                       | Brand          | Deployment  |
| -------------------------- | --------------------------- | ---------- | ------------------------------------------------------- | --------------------------------------------------------------- | -------------- | ----------- |
| **MinerU**                 | MinerU                      | /          | Processing PDF files into Markdown for model use        | Intelligent PDF parsing                                         | OpenDataLab    | On-premise  |
| **Qwen**                   | Qwen-Image                  | /          | Supporting tools: image generation                      | Text-to-image, image-to-image                                   | Alibaba        | On-premise  |
| **Qwen**                   | Qwen-Image-Edit             | /          | Supporting tools: image editing                         | Image retouching, inpainting                                    | Alibaba        | On-premise  |
| **BAAI General Embedding** | bge-reranker-v2-m3          | Re-ranker  | Corpus RAG re-ranking support                           | Fast multilingual re-ranking                                    | BAAI Institute | On-premise  |
| **BAAI General Embedding** | bge-m3                      | Embedding  | Corpus RAG document preprocessing and retrieval support | Multilingual vectorization                                      | BAAI Institute | On-premise  |

[^4]: The `Image Generation` and `Image Editing` (enable via the toolbar below the chat window) features invoke Qwen-Image/Qwen-Image-Edit. These run on-premise and are not billed.
[^5]: Models are being rolled out gradually based on usage. Not all models may be currently visible. Availability is subject to the platform display.
[^6]: GPT-5 Auto is a collection of models. During responses, computational resources are dynamically allocated, and different models may be used. The responding model is not necessarily "GPT-5." This is OpenAI's commercial strategy, not a design flaw on our part.
[^7]: Additional paid activation. Please contact ITSO.

> Note: The prices above are token-based unit prices, shown per “one million tokens (1M tokens).” “Cache” refers to vendor-supported cached input tokens. Actual charges are based on vendor metering and the platform’s billing.
> Special billing item: `title-generation` runs on Qwen3‑VL.

??? tip "Billing & Usage Notes"

    - Billing typically consists of **input tokens**, **cached input tokens** (if any), and **output tokens**, each billed at its respective unit price, then summed up.
    - Currencies may be **CNY (¥)** or **USD (\$)**; for cross-currency totals, the platform converts according to the settlement standard.
    - When calls include **tools/services** (e.g., web search), they are billed **per request**.

#

# Model Selection Guide

This guide compares nine AI conversational models available on our platform: **Qwen3-VL**, **DeepSeek V3**, **DeepSeek R1**, **GPT-5 (Auto)**, **GPT-5 (Thinking)**, **GPT-4.1**, **Gemini 2.5 Pro**, **Gemini 2.5 Flash**, and **Doubao Seed 1.6**. The purpose is to help users understand the key advantages and suitable use cases of each model, analyze their characteristics in terms of performance and application, and provide recommendations. Users can select the most appropriate model based on their individual needs.

??? tip "Performance: Generation Quality and Reasoning Capability"

    Different models excel in response quality, logical reasoning, and handling specialized tasks. Below is an overview of each model's performance:

    - **Qwen3-VL:** A **large Mixture-of-Experts (MoE) model** developed by Alibaba Cloud's Qwen team, with 235 billion total parameters (approximately 22 billion activated per inference). It excels in **instruction following, logical reasoning, mathematics, science, programming, and tool usage**. Compared to its predecessor, Qwen3-VL shows significant improvements in **complex tasks** and extends context length to **262,144 tokens (approximately 256K)**. In benchmark tests, its overall capabilities **rival leading closed-source models (e.g., GPT-4 series and Claude)**, particularly excelling in reasoning, programming, and multilingual tasks. This model operates in **non-"thinking" mode**, delivering answers directly without lengthy reasoning delays.

    - **DeepSeek V3:** An open-source large model released by DeepSeek, using an MoE architecture with 671 billion total parameters but activating only about 37 billion per token. This allows it to achieve **GPT-4-level reasoning capabilities** with lower computational overhead. DeepSeek V3 **outperforms most open-source models** in numerous benchmarks and **rivals top closed models** (e.g., GPT-4 series, Claude 3.5, Gemini Pro). It particularly excels in **mathematical reasoning and code generation**, achieving a high score of **82.6% on the HumanEval coding test**, comparable to GPT-4. Its reasoning and knowledge QA abilities are also excellent (88.5% accuracy on five MMLU evaluations). Overall, DeepSeek V3 is one of the few open-source models that matches GPT-4 in **general language understanding, QA, coding, and math**, while leveraging MoE architecture for **faster and more economical inference**.

    - **DeepSeek R1:** A customized **"reasoning-enhanced" version** based on V3. Optimized for **complex logic, mathematical reasoning, and step-by-step problem solving**, DeepSeek R1 incorporates advanced reinforcement learning strategies during training, enabling outputs with **structured, explainable chain-of-thought** processes. Unlike V3, which provides direct answers, R1 tends to **show clear reasoning steps**, i.e., Chain-of-Thought (step-by-step thinking), to help users understand how answers are derived. This makes R1 ideal for tasks requiring **rigorous logical deduction or multi-step calculations**, such as complex math problems, logic puzzles, or program debugging. If your query involves reasoning, multi-step planning, or tool usage, R1 often provides more thorough processes and more accurate results than V3. However, due to increased computational and procedural overhead, R1's response speed is slightly slower than V3, making it suitable for **in-depth analysis scenarios**.

    - **GPT-5 (Auto):** OpenAI's latest general-purpose model released in 2025. GPT-5 introduces a **unified multi-model architecture**; from the user's perspective, it appears as a single "GPT-5," but the system **automatically allocates computational resources** based on the query. Simple everyday questions are answered by fast models, while complex problems trigger deeper reasoning sub-models. Thus, GPT-5 (Auto) **balances speed and intelligence**: for most routine conversations and content generation, it is **very fast and accurate**; for complex tasks, it seamlessly switches to a more powerful reasoning engine. Compared to the previous GPT-4.0, GPT-5 shows massive performance improvements across coding, reasoning, and other areas, significantly reducing "hallucination" errors (general factual errors reduced by approximately 45%). In code generation and analysis, GPT-5 surpasses all previous models, becoming the new **coding benchmark**; in complex scientific QA (e.g., research-level physics and math problems), GPT-5's accuracy reaches **85-89%**, far exceeding GPT-4's ~70%. Overall, GPT-5 in default mode is already **one of the strongest performers in general tasks**, providing high-quality responses at near real-time speed while offering some depth in reasoning when needed.

    - **GPT-5 (Thinking):** This is GPT-5's **deep reasoning mode**. For difficult problems or upon specific user request, GPT-5 can enter Thinking mode, investing more computation and time, akin to making the AI "slow down and think carefully." In this mode, GPT-5 employs advanced reasoning techniques such as **chain-of-thought** (providing intermediate reasoning steps), **self-consistency** (trying multiple solution paths and selecting the most credible answer), and even **tree-of-thought search** (exploring branching possibilities and pruning poor paths). These methods significantly enhance GPT-5's ability to solve complex problems and reduce error rates (deep thinking can further reduce factual errors by 80%). **Performance-wise**, Thinking mode is used for the most challenging tasks: it scores higher on difficult academic benchmarks than the default mode, serving as OpenAI's **quasi-professional-grade** reasoning engine. For example, in complex domains like medicine or law, GPT-5 Thinking mode can reduce error rates to **within 1-2%**, whereas GPT-4 might have error rates as high as 15-20%. Note that enabling Thinking mode **significantly slows response speed** and may only be available under specific advanced subscriptions or API parameters. However, when **accuracy and depth are paramount**, GPT-5 Thinking mode is among the most powerful choices available.

    - **GPT-4.1:** An enhanced version of OpenAI's GPT-4 model released in 2025. GPT-4.1 improves upon GPT-4 in coding, instruction following, and multimodal understanding, serving as a **refined upgrade**. It features an astonishing **1 million token context window**, enabling it to process unprecedented input lengths. This equates to analyzing or summarizing thousands of pages of text in a single conversation, ideal for entire books or lengthy reports. GPT-4.1 also shows improvements in professional tasks: for instance, it achieves **54.6% accuracy** on the software engineering benchmark SWE-Bench, performing exceptionally well; in comprehensive instruction challenges (MultiChallenge), it scores **10.5% higher** than the older GPT-4. Overall, GPT-4.1 maintains GPT-4's strong general capabilities and remains top-tier in **code writing, complex QA, and creative writing**. Although its overall performance is slightly inferior to the newer GPT-5 series, GPT-4.1 is renowned for its stability and reliability, delivering **accurate and coherent** responses for most everyday and professional tasks. Additionally, its massive context window grants it a unique advantage in handling **extremely long documents and multi-turn conversations**, a feature unmatched by other models.

    - **Gemini 2.5 Pro:** Google’s high-end multimodal model, strong in **image+text understanding**, **table/chart interpretation**, and **visual grounding**. Balanced in Chinese/English with strong **multimodal reasoning**. Suitable for **rigorous visual+text joint analysis** (e.g., Q&A from screenshots, table interpretation). Quality approaches top-tier closed models; speed and price are mid-to-high.

    - **Gemini 2.5 Flash:** Lightweight and fast—**low latency and cost**—for **high-concurrency, real-time** use. Good for summaries, key point extraction, routine QA, and basic multimodal understanding. Compared to Pro, it trades off **complex reasoning/long chains** for speed/cost.

    - **Doubao Seed 1.6:** Optimized for Chinese-language scenarios with alignment toward domestic business use. It balances **value and stability**, making it suitable for **Chinese tasks**.

??? tip "Use Cases: Applicable Scenarios"

    Different models excel in different domains and applications. Based on their training characteristics and capabilities, we summarize the following use cases:

    - **Qwen3-VL:** Suitable for **broad general-purpose generation tasks**. Excelling in instruction following and knowledge coverage, it handles various scenarios from **article writing** (narrative creation, copy editing) to **complex QA** (science communication, multi-domain knowledge consultation). It is also strong in **programming**, useful for code snippet generation, debugging suggestions, and technical QA. Qwen3 offers a **256K ultra-long context**, ideal for tasks requiring **very long text processing**, such as **long document analysis**, **report summarization**, and **novel continuation**. Its **multilingual capabilities** are outstanding, performing well in bilingual (e.g., Chinese-English) or multilingual scenarios like mixed-language QA and translation. For example, if you need the AI to read a several-hundred-thousand-character document and answer questions, Qwen3 can accommodate this content in a single conversation, which models with limited context cannot achieve.

        !!! danger "Prevent Confidential Data Leakage"

            **Some companies in the market (e.g., OpenAI) offering large model API services require users to explicitly agree to "allow query content to be used as model training data" as a condition of use.**

            Our selected suppliers commit to **not using or retaining user query data for AI training**.

            However, for security reasons, **only** use `Qwen3-MoE (Local Edition)` for handling confidential data that must not be disclosed externally. **This is the only option for handling sensitive data.** Except when using `web search` and `image generation`, if you **exclusively** select the Qwen3-MoE model throughout, your data will be strictly processed on our on-campus servers and will not be leaked externally.

    - **DeepSeek V3:** As a general-purpose model, DeepSeek V3 excels in **content creation, summarization, and QA** for **daily applications**. Its strength in **logical reasoning** and **computation** makes it highly practical in **academic and research** settings. For example, it can be used for **extracting key points from academic papers**, **interpreting data reports**, or **knowledge QA** (covering broad fields like history, law, and science) with detailed explanations. DeepSeek V3 is also proficient in **code generation and debugging**, applicable in **programming assistance** and **code review** for technical development. Furthermore, its capabilities in **mathematics** and **logic puzzles** surpass previous models, suitable for solving complex math competition problems and providing formula derivation steps. If your application requires a **versatile** open-source assistant for **writing, translation, conversation**, or **deploying an AI agent locally** to handle various tasks, DeepSeek V3 is an ideal choice. It also supports a **maximum context of approximately 128K**, sufficient for most long-document summarization and multi-turn conversation needs.

    - **DeepSeek R1:** A model designed specifically for **in-depth reasoning**, ideal for scenarios requiring **rigorous thinking**. It outputs **step-by-step reasoning processes**, making it highly valuable in **education and research**—for example, as a **math problem-solving assistant** that explains how to solve complex problems step by step, or as a **logic coach** analyzing reasoning puzzles and logic games. For AI applications that **require explanation of processes** (e.g., *"Please tell me how to solve this problem and explain each step"*), DeepSeek R1 is more valuable than models that only provide final answers. It is also well-suited for **programming debugging**—not only suggesting code but also explaining debugging strategies or algorithmic logic. In other words, if your use case emphasizes **transparency and reliability of the process**, such as in education, complex consulting (legal reasoning, financial analysis), R1 can meet these needs through **detailed thought exposition**. Note that due to built-in self-correction and multi-round reasoning, R1 has unique advantages in **interactive agents** or **automated problem-solving** scenarios (e.g., letting the AI autonomously plan step-by-step actions).

    - **GPT-5 (Auto):** A **versatile** conversational model suitable for most everyday and professional scenarios. For ordinary users, GPT-5 serves as a **highly intelligent chat assistant**: whether drafting emails, providing creative writing inspiration, daily knowledge QA, or language translation, it quickly delivers high-quality content. It excels in **business copywriting** and **marketing content generation**, capable of writing report summaries, product descriptions, etc., based on user requirements. In **programming** scenarios, GPT-5 can write code, explain code snippets, help resolve programming errors, and even generate complete code modules from natural language descriptions, making it a powerful assistant for developers. Additionally, in **academic research** and **professional domains**, GPT-5 is useful for summarizing research literature, analyzing data trends, and providing medical or legal knowledge consultation. Thanks to **automatic mode switching**, GPT-5 responds extremely fast to simple tasks and can invoke its deep reasoning capabilities for complex tasks (e.g., analyzing long documents, solving difficult problems). Therefore, whether for **quick daily conversations** or **complex high-end applications** (e.g., having the AI review a 100-page report and provide insights), GPT-5 (Auto) mode is capable. It is a **default preferred** general-purpose model, suitable for **individual** and **enterprise users** across various scenarios.

    - **GPT-5 (Thinking):** This mode is intended for **difficult problems and high-stakes tasks**. When the standard mode cannot ensure high-quality answers, GPT-5 can enter Thinking mode to obtain **deeper and more reliable** results. For example, in **research** or **business decision-making** scenarios, you can ask GPT-5 to analyze complex situations in detail, propose solutions, and provide reasoning. In **medical** consultations, the Thinking mode can more robustly analyze symptoms and literature to offer accurate advice. Similarly, when requiring the AI to **autonomously plan solutions** or **execute complex multi-step instructions** (e.g., writing a lengthy program or conducting logical arguments), the Thinking mode will proceed step by step, reducing the likelihood of errors. In short, when tasks involve **highly complex logic, multi-stage inference, or highly specialized problems**, enabling GPT-5 Thinking mode is safer. Remember that its response speed is slower, making it suitable for **quality-over-speed** applications. Ordinary users typically do not need to manually select this in the ChatGPT interface—the system automatically enables deep thinking based on question complexity; however, in advanced interfaces or professional subscriptions, you can explicitly specify the Thinking mode to ensure **foolproof solutions**.

    - **GPT-4.1:** Although not the latest generation, this model remains **practical and efficient** in many scenarios. First, it is ideal for **processing extremely long content**: if you need the AI to read and summarize a book, a contract or technical specification dozens of pages long, GPT-4.1's million-token context window makes it highly capable. In **code assistance**, GPT-4.1 can write and understand complex code, having been one of the top code AIs in 2024-2025, and remains reliable for everyday programming Q&A and algorithm explanations. Additionally, due to enhanced fine-tuning, its **response style is stable**, performing **mature and reliable** in creative writing, encyclopedic QA, and educational tutoring. For **multi-turn conversation** tasks (e.g., long-term project discussions, role-playing dialogues), GPT-4.1's longer memory context also provides a coherent experience, less prone to forgetting prior context. Overall, if you do not require the cutting-edge performance of the latest GPT-5 or are considering **budget** constraints, GPT-4.1 remains a **comprehensive** AI assistant, supporting most application scenarios from **daily communication** to **professional domains**. Moreover, after the release of OpenAI's newer models, GPT-4.1 may offer **more affordable pricing** or **fewer usage restrictions**, making it a viable choice for users seeking advanced AI capabilities while **controlling costs**.

    - **Gemini 2.5 Pro:** Ideal for **complex image+text understanding** (reports with screenshots/tables/charts), **cross-modal comparison**, and **reliable visual inference**. Prefer Pro when you require **strong visual information extraction** and **cross-modal linking** (e.g., summarizing slide images and tying them to a text report).

    - **Gemini 2.5 Flash:** Best for **low-cost, high-throughput** summarization, key point extraction, entity extraction, basic translation, and fast QA. Also suitable for **low-latency** apps (e.g., conversational support prototypes, streaming answers).

    - **Doubao Seed 1.6:** A **stable** general assistant for **Chinese business workflows**, good for **Chinese writing**, **business document generation**, and **rules/policy QA**. High value for money.

??? success "Summary: Key Advantages and Model Selection Guide"

    **Summary of Selection Criteria:**

    - For everyday quick conversations, select `Qwen3-MoE (Local Edition)` (default option). Its ultra-long context and very fast response make it the preferred choice for knowledge acquisition.
    - For complex reasoning tasks, choose `DeepSeek` with **reasoning enabled**.
    - If unsatisfied with Qwen3's response, try `GPT-5 Auto` or `DeepSeek` (without reasoning enabled).
    - For very difficult or highly complex logical problems, select `GPT-5 Thinking`. Note that response time will be very long.
    - `DeepSeek` (without reasoning) and `GPT-4.1` can serve as alternative options for independent exploration.
    - For **image+text multimodal understanding**, prefer `Gemini 2.5 Pro`; for **cost/speed**, choose `Gemini 2.5 Flash`.
    - For **Chinese business scenarios**, choose `Doubao Seed 1.6`.

    In conclusion, there is no one-size-fits-all "best" model—only the **model most suitable for you**. We hope this guide's comparative analysis helps you find the model that meets your objectives. We wish you an excellent experience in your future use!
