---
hide:
  - navigation
  - toc
---

# 对话模型

对话模型是您可以在左上角的模型选择中选择到的模型。[^5]

| 模型系列                 | 模型名称                 | 实际模型                            | 模型类型   | 擅长领域                   | 上下文长度（Tokens） | 回答速度 | 计费   | 价格（每百万 Tokens）            | 品牌方   | 部署方式     |
| ------------------------ | ------------------------ | ----------------------------------- | ---------- | -------------------------- | -------------------- | -------- | ------ | ------------------------------- | -------- | ------------ |
| **千问**                 | Qwen3-MoE（本地版）  | `qwen3-vl-235b-a22b-instruct`       | 多模态     | 通用对话                   | 128,000            | 快       | **无** | 输入/缓存/输出：￥2.00/￥0.50/￥8.00（平台免费） | 阿里巴巴 | 本地部署     |
| **深度求索**             | DeepSeek                 | `DeepSeek V3 671B`                  | 多模态[^1] | 通用对话                   | 96,000              | 中       | 低     | 输入/缓存/输出：￥2.00/￥0.40/￥8.00 | 深度求索 | API (火山云) |
| **深度求索**             | DeepSeek（开启深度思考） | `DeepSeek R1 671B`                  | 多模态[^1] | 复杂数学 复杂逻辑推理      | 64,000              | 慢       | 低     | 输入/缓存/输出：￥4.00/￥0.80/￥16.00| 深度求索 | API (火山云) |
| **GPT**                  | GPT-5 Auto[^6]           | `GPT-5 Chat`                        | 多模态     | 通用对话 自动推理 快速响应 | 128,000             | 快       | 中     | 输入/缓存/输出：\$1.25/\$0.125/\$10.00 | OpenAI   | API (Azure)  |
| **GPT**                  | GPT-5 Thinking           | `GPT-5`                             | 多模态     | 复杂推理 深度思考 问题分析 | 400,000             | 慢       | 高     | 输入/缓存/输出：\$1.25/\$0.125/\$10.00 | OpenAI   | API (Azure)  |
| **GPT**                  | GPT-4.1                  | `GPT-4.1`                           | 多模态     | 编程 长上下文 通用推理     | 1,047,576           | 中       | 高     | 输入/缓存/输出：\$2.00/\$0.50/\$8.00   | OpenAI   | API (Azure)  |
| **Gemini**               | Gemini 2.5 Pro           | `Gemini 2.5 Pro`                    | 多模态     | 通用对话 多模态理解        | 128,000             | 中       | 高     | 输入/缓存/输出：\$2.50/\$0.625/\$15.00 | Google   | API (Google) |
| **Gemini**               | Gemini 2.5 Flash         | `Gemini 2.5 Flash`                  | 多模态     | 通用对话 快速响应          | 128,000             | 快       | 低     | 输入/缓存/输出：\$0.30/\$0.075/\$2.50  | Google   | API (Google) |
| **Doubao Seed**          | 豆包 Seed 1.6            | `Doubao Seed 1.6`            | 多模态     | 通用对话                   | 96,000              | 中       | 中     | 输入/缓存/输出：￥0.80/￥0.16/￥8.00  | 火山引擎 | API (火山云) |
| **OpenAI Deep Research** | OpenAI 深度研究[^7]      | `OpenAI Deep Research`              | /          | 联网搜集资料并汇总         | N/A                 | 极慢     | 极高   | 输入/缓存/输出：\$10.00/\$2.50/\$40.00 | OpenAI   | API (Azure)  |

<!-- 未上线的 -->
<!-- | **xAI**                 | Grok-4                   | `grok-4`                            | 多模态     | 通用对话 推理              | 中       | 高     | 输入/缓存/输出：\$3.00/\$3.00/\$15.00  | xAI      | API (xAI)    | -->
<!-- | **Doubao Seed**          | 豆包 Seed 1.6 Thinking        | `doubao-seed-1-6-thinking-250715`   | 多模态[^1] | 复杂推理 深度思考          | 慢       | 高     | 输入/缓存/输出：￥1.20/￥0.16/￥16.00 | 火山引擎 | API (火山云) | -->

#

# 基座模型

这些模型支撑 GPT 服务平台的基础功能。

| 模型系列                   | 实际模型                    | 模型类型 | 用途                                    | 擅长领域                           | 品牌方          | 部署方式    |
| -------------------------- | --------------------------- | -------- | --------------------------------------- | ---------------------------------- | --------------- | ----------- |
| **MinerU**                 | MinerU                      | /        | 处理 PDF 文件，转为 Markdown 供模型处理 | PDF 智能解析                       | OpenDataLab     | 本地部署    |
| **千问**                   | Qwen-Image                  | /        | 支持工具：图像生成                      | 文生图、图生图                     | 阿里巴巴        | 本地部署    |
| **千问**                   | Qwen-Image-Edit             | /        | 支持工具：图像编辑                      | 图像润色、局部编辑                 | 阿里巴巴        | 本地部署    |
| **BAAI General Embedding** | bge-reranker-v2-m3          | 重排序   | 语料库 RAG 重排序支持                   | 快速多语言重排                     | BAAI 智源研究院 | 本地部署    |
| **BAAI General Embedding** | bge-m3                      | 嵌入     | 语料库 RAG 文档预处理、检索处理支持     | 多语言向量化                       | BAAI 智源研究院 | 本地部署    |

[^4]: 使用 `图像生成`、`图像编辑`（开启对话框下方工具栏 `图像生成`） 功能时，调用 Qwen-Image/Qwen-Image-Edit，本地部署，不计费。
[^5]: 模型正在根据使用情况逐步开放。当前可能无法看到所有的模型。请以平台显示为准。
[^6]: GPT-5 Auto 是一组模型的集合，回答时会自动调配计算资源，使用不同的模型，即参与应答的模型不一定是“GPT-5”。这是 OpenAI 的商业策略，而非我们的错误设计。
[^7]: 额外付费开通。请联系ITSO。

> 说明：以上价格为按 Tokens 计费的单价，单位为“每百万 Tokens（1M Tokens）”。“缓存”指供应商支持的缓存输入（Cached Tokens）。实际费用以平台计费与供应商计量为准。
> 特殊计费项：`title-generation` 基于 Qwen3‑VL。

??? tip "计费与用量说明"

    - 计费维度分为**输入 Tokens**、**缓存输入 Tokens**（如有）与**输出 Tokens**，三部分分别按对应单价计费并累加。
    - 币种可能为**人民币（CNY）**或**美元（USD）**；若涉及跨币种汇总，平台会根据结算口径折算显示。
    - 若调用包含**工具/服务**（如联网搜索），按**次数**另行计费。

#

# 模型选择指南

本篇指南中，我们对九款我们平台提供的 AI 对话模型进行比较：**Qwen3-VL**、**DeepSeek V3**、**DeepSeek R1**、**GPT-5 (Auto)**、**GPT-5 (Thinking)**、**GPT-4.1**、**Gemini 2.5 Pro**、**Gemini 2.5 Flash** 和 **Doubao Seed 1.6**。本文旨在帮助普通用户理解各模型的关键优点、适用场景，从性能和用途方面逐一分析每个模型的特点，给出我们的选择建议。您可以根据个人需求选择最合适的模型。

??? tip "性能：生成质量与推理能力"

    不同模型在回答质量、逻辑推理和专业任务处理上各有所长。以下是各模型性能的概览：

    - **Qwen3-VL：** 由阿里云Qwen团队开发的**超大型Mixture-of-Experts模型**，总参数2350亿（每次推理激活约220亿）。它在**遵循指令、逻辑推理、数学、科学、编程和工具使用**等方面表现出色。相比前代版本，Qwen3-VL在各类**复杂任务**上显著提质提效，并将上下文长度扩展至**262144个Token（约256K）**。在基准测试中，它的综合能力**可与领先的封闭源模型（如GPT-4系列和Claude等）相媲美**，尤其在推理、编程和多语言任务上表现突出。该模型采用**非“思考”模式**，答案直出，没有烦人的推理耗时。

    - **DeepSeek V3：** DeepSeek发布的开源大模型，采用MoE架构，总参数高达6710亿，但每个Token只激活约370亿参数。这使其**具备GPT-4级别的推理能力**，却能以较低的计算负载运行。DeepSeek V3在众多基准上**超越了多数开源模型，并可媲美顶尖的封闭模型**（如GPT-4系列、Claude 3.5、Gemini Pro等）。尤其在**数学推理和代码生成**方面表现卓越：例如在编码测试HumanEval上达到**82.6%的高分**，与GPT-4旗鼓相当。它的推理和知识问答能力同样优异（MMLU五次测评正确率88.5%）。总体而言，DeepSeek V3是少数能在**通用语言理解、问答、代码和数学**等领域媲美GPT-4的开源模型之一，同时利用MoE架构实现了**更快且更经济的推理**。

    - **DeepSeek R1：** 这是在V3基础上定制的**“推理加强”版本**。DeepSeek R1专为**复杂逻辑、数学推理和逐步求解问题**优化。它在训练中增加了高级强化学习策略，使输出具备**结构化、可解释的链式思考**流程。与V3直接给出答案不同，R1倾向于**给出步骤清晰的推理过程**，即所谓的Chain-of-Thought（逐步思考）解释，以帮助理解答案是如何得到的。这使R1非常适合需要**严密逻辑推导或多步骤计算**的任务，比如复杂数学题、逻辑推理题、程序调试等。如果你的问题涉及推理、多步骤规划或工具使用，R1往往能提供比V3更缜密的过程和更准确的结果。不过，由于R1在推理上投入更多计算和步骤，它的响应速度相对V3略慢，适合在**需要深度分析时**再予以调用。

    - **GPT-5 (Auto)：** OpenAI于2025年推出的最新一代通用模型。GPT-5引入了**统一的多模型架构**，在用户看来的只是“GPT-5”，但系统会根据提问**自动调配计算资源**。简单日常问题用快速模型解答，而遇到复杂问题则自动启用深入推理的子模型。因此，GPT-5 (Auto)模式能够**兼顾速度和智力**：对于大多数普通对话和内容生成，它表现得**非常快且准确**；在复杂任务上，它能无缝切换到更强大的推理引擎。与上一代GPT-4.0相比，GPT-5整体性能有巨大飞跃——编码、推理等各方面均有提高，并大幅减少了“幻觉”错误（一般事实性错误减少约45%）。在代码生成和分析上，GPT-5击败此前所有模型，成为新的**编码标杆** ；在复杂科学问答（如研究级物理、数学题）上，GPT-5的准确率可达**85-89%**，远高于GPT-4的约70% 。总体而言，GPT-5默认模式下已经是**目前通用任务表现最强**的模型之一，能够以接近实时的速度提供高质量回答，同时在需要时具有一定的推理深度。

    - **GPT-5 (Thinking)：** 这是GPT-5的**深度推理模式**。当遇到疑难问题或在用户特别要求下，GPT-5可以进入Thinking模式，投入更多计算和时间，类似让AI“慢下来仔细思考”。在Thinking模式下，GPT-5会运用一系列**高级推理技术**：例如**链式思维**（分步给出中间推理步骤）、**自一致性**（尝试多种解题路径取最可信的答案）甚至**思维树搜索**（探索分支可能并剪枝不良路径）等。通过这些方法，GPT-5的复杂问题解答能力大幅提升，错误率显著降低（深度思考可将事实错误再减少80%）。**性能上**，Thinking模式常用于最棘手的任务：它在困难学术基准上的得分比默认模式进一步提高，是OpenAI提供的**准专业级**推理引擎。例如，在需要深入分析的医学、法律等领域问题上，GPT-5 Thinking模式能将错误率压低到**1-2%以内**，而GPT-4此类场景下错误率可能高达15-20% 。需要注意的是，启用Thinking模式会**明显减慢响应速度**，并可能只在特定高级订阅或API参数下可用。但当**准确性和深度最为关键**时，GPT-5 Thinking模式堪称目前业界最强大的选择之一。

    - **GPT-4.1：** 这是OpenAI GPT-4模型在2025年的增强版本。GPT-4.1针对编码、指令遵循和多模态理解等方面进行了改进，被视为GPT-4的**精炼升级版**。它引入了一个惊人的**100万Token上下文窗口**，能处理前所未有长度的输入。换算下来，这约等于单次对话可容纳数千页文本，方便模型对整本书或超长报告进行分析总结。GPT-4.1在专业任务上也有所提升：例如在软件工程基准测试SWE-Bench上正确率达到**54.6%**，表现出色；在综合指令挑战（MultiChallenge）中，比旧版GPT-4提高了**10.5%**的得分。总体来说，GPT-4.1延续了GPT-4强大的通用能力，在**代码编写、复杂问答、创意写作**等方面依然是一流的。尽管其综合性能稍逊于更新的GPT-5系列，但GPT-4.1以稳定可靠著称，对大部分日常和专业任务仍能给出**准确且连贯**的回答。同时，庞大的上下文窗口也赋予它在处理**超长文档和多轮对话**时的独特优势，这一点是其他模型所不及的。

    - **Gemini 2.5 Pro：** Google 最新的多模态高阶模型，在**图文理解、表格/图表解读、视觉定位**等方面表现稳健，中文英文均衡，**多模态推理**能力突出，适合需要**严谨的视觉+文本**联合分析的任务（如读图答题、截图/表格解读）。

    - **Gemini 2.5 Flash：** 轻量快速版本，**响应速度快、成本低**，面向**高并发与实时响应**场景。适合摘要、要点提取、普通问答与基础多模态理解。与 Pro 相比，不需要思考，输出速度更快。

    - **Doubao Seed 1.6：** 面向中文生态优化，语料与对齐偏向中文业务场景，兼顾**性价比与稳定性**。适合**中文任务**的使用场景。

??? tip "用途：适用的应用场景"

    不同模型各有擅长的领域和应用场景。根据它们的训练特点和能力，我们总结了以下适用用途：

    - **Qwen3-VL：** 适合**广泛的通用生成任务**。由于在指令遵循和知识覆盖方面表现优异，它能胜任从**文章写作**（叙事创作、文案润色）到**复杂问答**（科普解答、多领域知识咨询）的各种场景。它在**编程**上也有强项，可用于代码片段生成、调试建议和技术问答。Qwen3提供了**256K超长上下文**，非常适合诸如**长文档分析**、**报告总结**、**小说续写**等需要处理**超长文本**的任务。同时，其**多语言能力**突出，对于涉及中英双语乃至其他语言内容的场景（如中英混合问答、多语言翻译）也有良好表现。举例来说，如果你需要让AI阅读一本几十万字的资料然后回答问题，Qwen3能在单次对话中容纳这些内容并给出结果，这是一般上下文长度有限的模型无法做到的。

        !!! danger "谨防机密数据外泄"

            **目前市面上有部分公司（例如OpenAI）提供大模型API服务时，强制要求用户同意“允许将提问内容作为模型训练数据”，否则无法使用。**

            我们选择的供应商承诺**不会使用、保留用户的提问数据用于AI训练**。

            但出于安全考虑，请**仅**使用`Qwen3-MoE（本地版）`处理不能对外泄漏的机要数据。**这是处理机密数据的唯一选择。**除使用`联网搜索`和`图像生成`外，若**全程**选择Qwen3-MoE模型，您的数据将严格在校内服务器上处理，不会外泄。

    - **DeepSeek V3：** 作为通用模型，DeepSeek V3擅长**内容创作、总结和问答**等**日常应用**。它在**逻辑推理**和**计算**上能力突出，因此在**学习和科研**场景中也很实用。例如，它可用于**学术论文的要点提取**、**数据报告的解读**，或者**知识问答**（涵盖历史、法律、科学等广泛领域）并提供详尽解释。DeepSeek V3还以**代码生成和调试**见长，可应用于**编程助手**、**代码审核**等技术开发场景。另外，DeepSeek V3在**数学**和**逻辑题**方面的能力远超以往模型，适合用来解答复杂的数学竞赛题、提供公式推导步骤等。如果你的应用需要一个**全能型**的开源助手来进行**写作、翻译、对话**，或者**在本地部署一个AI代理**处理各种任务，DeepSeek V3都是理想之选。它还支持**最长约128K的上下文**，足以应对大部分长文档摘要和多轮对话需求。

    - **DeepSeek R1：** 专为**深入推理**设计的模型，非常适合需要**严谨思考**的场景。它能够输出**逐步推理过程**，因此在**教学和研究**中大有可为——例如用于**数学解题助理**，一步步讲解复杂的数学题如何求解；或充当**逻辑教练**，分析推理谜题、逻辑游戏的思路。对于**需要解释过程**的AI应用（如：*“请告诉我这道题怎么做，并解释每一步”*），DeepSeek R1会比只给最终答案的模型更有价值。它在**编程调试**方面也很适合——不仅给出代码建议，还能阐述调试思路或算法逻辑。换句话说，如果你的使用场景重视**答案的透明度和过程可靠性**，例如教育场景、复杂咨询（法律推理、财务分析等），R1 能通过**详尽的思路展开**来满足需求。需要注意R1由于内置了自我纠错和多轮推理，在**交互式代理**或**自动问题求解**类场景（如让AI自行规划分步行动）中也有独特优势。

    - **GPT-5 (Auto)：** 这是一款**全能型**对话模型，适用于绝大多数日常和专业场景。对普通用户而言，GPT-5可作为**高度智能的聊天助手**：无论是撰写电子邮件、提供创意写作灵感，还是日常知识问答、语言翻译，它都能快速给出高质量内容。它在**商业文案**、**市场营销内容**生成上也很擅长，可以根据用户要求写报告摘要、产品描述等。对于**编程**场景，GPT-5能够编写代码、解释代码片段，帮助解决程序错误，甚至基于自然语言描述生成完整的代码模块，是开发者的强力助手。此外，在**学术研究**和**专业领域**，GPT-5也能派上用场：比如总结研究文献、分析数据趋势、提供医学或法律知识咨询等。得益于**自动模式切换**，GPT-5在简单任务上反应极快，而面对复杂任务（如长文档分析、难题求解）时又能调用其深入推理能力。因此，无论是**快速日常对话**，还是**复杂高端应用**（如让AI审阅100页报告并提出见解），GPT-5 (Auto)模式都能胜任。它是一款**默认首选**的通用模型，适合**个人用户**和**企业用户**在各种场景下使用。

    - **GPT-5 (Thinking)：** 此模式专供**疑难问题和高要求任务**使用。当普通模式无法确保高质量解答时，可以让GPT-5进入Thinking模式，以获取更**深度可靠**的结果。例如，在**科研**或**商业决策**场景中，你可以要求GPT-5详细分析复杂局面，提出方案并给出推理依据；在**医疗**咨询中，Thinking模式可以更稳健地分析病症和文献，从而提供准确的建议。又如当需要AI**自主规划方案**或**执行复杂多步骤指令**时（比如编写一段较长的程序或进行推理论证），Thinking模式将逐步演绎，减小犯错几率。简而言之，当任务涉及**高度复杂的逻辑、多阶段推断或高度专业化的问题**，启用GPT-5 Thinking模式会更保险。需要记住它的响应速度较慢，适合**以质量优先于速度**的用途。一般个人用户在ChatGPT界面提问时无需手动选择——系统会视问题复杂度自动启用深度思考；但在一些高级接口或专业订阅中，你也可以明确指定使用Thinking模式，以确保**万无一失的解决方案**。

    - **GPT-4.1：** 这款模型虽然不是最新一代，但在许多场景下仍然**实用高效**。首先，它非常适合**超长内容处理**：如果你需要AI阅读并总结一本书、一份长达数十页的合同或技术规范，GPT-4.1 的百万级上下文窗口使之游刃有余。在**代码助理**方面，GPT-4.1可以编写和理解复杂代码，曾是2024-2025年顶尖的代码AI之一，对于日常的程序开发问答、算法解释依然可靠。同时，GPT-4.1因经过强化调教，其**回答风格稳健**，在创意写作、百科问答、教育辅导等场景中表现**成熟而稳妥**。对于**需要多轮对话**的任务（如长期的项目讨论、角色扮演对话等），GPT-4.1 较长的记忆上下文也能带来连贯体验，不易遗忘前文。总体来说，如果你不追求最新GPT-5的尖端性能或者在**预算**上考虑，GPT-4.1依旧是**功能全面**的AI助手，可支持从**日常交流**到**专业领域**的大多数应用场景。此外，在OpenAI新版模型推出后，GPT-4.1可能在**定价**或**使用限制**上更为亲民，对于想体验高级AI能力又**控制成本**的用户，它是值得考虑的选择。

    - **Gemini 2.5 Pro：** 适合**图文结合的复杂理解**（报告含截图/表格/图表）、**多模态数据比对**。

    - **Gemini 2.5 Flash：** 适合**低成本、简单**的摘要、提要、实体抽取、基础翻译与快速问答。

    - **Doubao Seed 1.6：** 面向**中文业务流程**的**稳定型**通用助手，适合**中文写作**、**业务文档生成**、**规则/政策类问答**等场景，性价比较高。

??? success "总结：关键优点与模型选择指南"

    **选择依据总结：**

    - 日常快速对话选择 `Qwen3-MoE（本地版）`（默认选项）即可，超长上下文与非常快速的响应，使其成为获取知识的首选。
    - 涉及到复杂问题的推理时，可以选择 `DeepSeek` 并 **开启推理**。
    - 若对 Qwen3 的回答不满意，可以选择 `GPT-5 Auto` 或 `DeepSeek`（不开启推理）尝试解答。
    - 当问题非常困难或者逻辑非常复杂时，可以选择 `GPT-5 Thinking`。但请注意，模型回答的时间非常长。
    - `DeepSeek`（不开启推理）和 `GPT-4.1` 可以作为备选的选项自主探索。
    - 侧重**图文多模态理解**时优先 `Gemini 2.5 Pro`；强调**成本/速度**时选 `Gemini 2.5 Flash`。
    - 中文业务选 `Doubao Seed 1.6`。

    总之，没有“一刀切”的最好模型，只有**最适合你的模型**。希望本指南的比较分析能帮助你找到满足你使用目标的模型。祝你在未来的使用中获得出色的体验！
